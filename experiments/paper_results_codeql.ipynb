{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '/home/jovyan/work/core') \n",
    "import core_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labelled dataset \n",
    "# This consists of 3k annotated API methods \n",
    "# These are the methods that we will use to train the model\n",
    "\n",
    "df_labels = pd.read_csv('../inputs/new_API.csv',index_col=None)\n",
    "df_labels.drop_duplicates(subset=['keys'],keep='first',inplace=True)\n",
    "true_labels = dict(zip(df_labels['keys'],df_labels['real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficacy of representation  \n",
    "### Section 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- The full table is in outputs/format_evaluation_precision.csv\n",
    "- Run the cells below to read/reproduce the data for this plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83091759c619400b93aea5efb21a78b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4f3e789c814aec83c00972cee2e0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79064ffd24894037ac8272d173cdc398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc73108fc30481889967597cc4e83f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b640cc036744109f8db756ec86eacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07c016349c24840b7bd66224dd1864b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a744e342a24816b087196f2156d729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed25fe95d2f4a74a28daedb873a52c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95def14a24c646368a625608bb84b5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71953d12a3f54ac8bda29c74dc9493d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c3098e09e24d0187b7e080e11d9bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dd8972186b4252a9abf4e8c3240f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85e2cec50994b08972d5bfe5c442d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d63714d4544d26a6872377643a0ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b403f7632641c484e226d4b923f119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################ Experiment_1 using pre-trained model ################\n",
    "\n",
    "# First we download the pre-trained model\n",
    "# This line takes some time\n",
    "sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# to save the model locally, run the following command\n",
    "# sbert.save(path='../embeddings/sent_bert/',model_name='all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['input','learning','accuracy','precision','recall','f1']\n",
    "\n",
    "\n",
    "# Name for the input dataset. Formats are ready for the embedding layer\n",
    "inputs = ['new_API.csv']\n",
    "base = '../inputs/'\n",
    "\n",
    "classifiers = []\n",
    "output = []\n",
    "\n",
    "for input in inputs:\n",
    "    # read input documentation\n",
    "    format = input.replace('.csv','')\n",
    "    df = pd.read_csv(base + input,index_col=None)\n",
    "    df.drop_duplicates(keep='first',inplace=True)\n",
    "    # true label here are from block 16\n",
    "    df['real'] = [true_labels[x] for x in df['keys']]\n",
    "    \n",
    "    # embed the method documentation\n",
    "    X_original = sbert.encode(df['keys'].values)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(df['real'].values)\n",
    "    label_encoded_y = label_encoder.transform(df['real'].values)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_original,\n",
    "                                    label_encoded_y, test_size=0.25, random_state=0) #\n",
    "\n",
    "    \n",
    "    # Run classifiers\n",
    "    \n",
    "    learning = 'logistic'\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(x_train, y_train)\n",
    "    classifiers.append(logisticRegr)\n",
    "    predicted = logisticRegr.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    \n",
    "    learning = 'svm'\n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(x_train, y_train)\n",
    "    classifiers.append(clf)\n",
    "    predicted = clf.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    learning = 'xgboost'\n",
    "    xgbc = xgb.XGBClassifier()\n",
    "    xgbc.fit(x_train, y_train)\n",
    "    classifiers.append(xgbc)\n",
    "    predicted = xgbc.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    learning = 'NN'\n",
    "    nn = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(64), random_state=1,max_iter=500)\n",
    "    nn.fit(x_train,y_train)\n",
    "    classifiers.append(nn)\n",
    "    predicted = nn.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])    \n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(output,columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>learning</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_API</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.968769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_API</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.832261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new_API</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new_API</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.968769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input  learning  accuracy  precision    recall        f1\n",
       "3  new_API        NN  0.962963   0.982456  0.958333  0.968769\n",
       "0  new_API  logistic  0.925926   0.815789  0.916667  0.832261\n",
       "1  new_API       svm  0.962963   0.833333  0.958333  0.866667\n",
       "2  new_API   xgboost  0.962963   0.982456  0.958333  0.968769"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = ['learning','input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform libraries experiments\n",
    "\n",
    "### Section 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 Experiments. Here we use the pre-trained models. \n",
    "# The approach here is to train the classifiers and then use the ones with best performance\n",
    "# to predict the labels for Google Play Services methods. \n",
    "\n",
    "inputs = ['new_API.csv']\n",
    "base = '../inputs/'\n",
    "header = ['input','learning','accuracy','precision','recall','f1']\n",
    "df_labels = pd.read_csv(f'{base}new_API.csv',index_col=None)\n",
    "df_labels.drop_duplicates(subset=['keys'],keep='first',inplace=True)\n",
    "true_labels = dict(zip(df_labels['keys'],df_labels['real']))\n",
    "# store the models for latter predictions\n",
    "classifiers = []\n",
    "output = []\n",
    "\n",
    "for input in inputs:\n",
    "    df = pd.read_csv(base + input,index_col=None)\n",
    "    df.drop_duplicates(keep='first',inplace=True)\n",
    "    df['real'] = [true_labels[x] for x in df['keys']]\n",
    "\n",
    "    # use the fine-tunned model if available. \n",
    "    sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "    \n",
    "    X_original = sbert.encode(df['docs'].values)\n",
    "    embedding = input.replace('.csv','').replace('3k_','')\n",
    "\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(df['real'].values)\n",
    "    label_encoded_y = label_encoder.transform(df['real'].values)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_original,\n",
    "                                         label_encoded_y, test_size=0.15, random_state=0) \n",
    "\n",
    "\n",
    "    learning = 'xgboost'\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    classifiers.append(model)\n",
    "    predicted = model.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([embedding,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    learning = 'NN'\n",
    "    nn = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(64), random_state=1,max_iter=500)\n",
    "    nn.fit(x_train,y_train)\n",
    "    classifiers.append(nn)\n",
    "    predicted = nn.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([embedding,learning,accuracy,precision,recall,f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset of Google Play Services libraries with the ground truth\n",
    "df_input = pd.read_csv('../inputs/test_experiment_libs_nodup_D.csv',index_col=False)\n",
    "df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((513, 768), (513,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first need to embed the documentation from the test set\n",
    "test_emb = sbert.encode(df_input['docs'].values)\n",
    "# encode the labels\n",
    "label_encoded_test_y = label_encoder.transform(df_input['classification'].values)\n",
    "test_emb.shape,label_encoded_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we make the predictions for the test set\n",
    "predictions = []\n",
    "output2 = []\n",
    "for clf,learning,embedding in [(classifiers[0],'xg','d'),(classifiers[1],'nn','d')]:\n",
    "    predicted = clf.predict(test_emb)\n",
    "    predictions.append(predicted)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(label_encoded_test_y, predicted)\n",
    "    output2.append([embedding,learning,accuracy,precision,recall,f1])\n",
    "df_results2 = pd.DataFrame(output2,columns=header)\n",
    "df_input['xg_new'] = label_encoder.inverse_transform(predictions[0])\n",
    "df_input['nn_new'] = label_encoder.inverse_transform(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we calculate the percentage of detected sources/sinks per library \n",
    "# table 5 is generated from this output\n",
    "totals = []\n",
    "lib_wear = df_input.loc[df_input.library == 'wearable']\n",
    "totals.append(['wear','sources',lib_wear.loc[(lib_wear.classification == 'sink')].shape[0], \\\n",
    "lib_wear.loc[(lib_wear.classification == 'sink') & (lib_wear.classification == lib_wear.xg_new) ].shape[0]])\n",
    "totals.append(['wear','sinks',lib_wear.loc[(lib_wear.classification == 'source')].shape[0], \\\n",
    "lib_wear.loc[(lib_wear.classification == 'source') & (lib_wear.classification == lib_wear.xg_new) ].shape[0]])\n",
    "\n",
    "lib_tv = df_input.loc[df_input.library == 'tv']\n",
    "totals.append(['tv','sources',lib_tv.loc[(lib_tv.classification == 'sink')].shape[0], \\\n",
    "lib_tv.loc[(lib_tv.classification == 'sink') & (lib_tv.classification == lib_tv.xg_new) ].shape[0]])\n",
    "totals.append(['tv','sources',lib_tv.loc[(lib_tv.classification == 'source')].shape[0], \\\n",
    "lib_tv.loc[(lib_tv.classification == 'source') & (lib_tv.classification == lib_tv.xg_new) ].shape[0]])\n",
    "\n",
    "analytic = df_input.loc[df_input.library.isin(['analytics'])]\n",
    "totals.append(['analytic','sources',analytic.loc[(analytic.classification == 'sink')].shape[0], \\\n",
    "analytic.loc[(analytic.classification == 'sink') & (analytic.classification == analytic.xg_new) ].shape[0]])\n",
    "totals.append(['analytic','sinks',analytic.loc[(analytic.classification == 'source')].shape[0], \\\n",
    "analytic.loc[(analytic.classification == 'source') & (analytic.classification == analytic.xg_new) ].shape[0]])\n",
    "\n",
    "ads = df_input.loc[df_input.library.isin(['ads'])]\n",
    "totals.append(['ads','source',ads.loc[(ads.classification == 'source')].shape[0], \\\n",
    "ads.loc[(ads.classification == 'source') & (ads.classification == ads.xg_new) ].shape[0]])\n",
    "totals.append(['ads','sink',ads.loc[(ads.classification == 'sink')].shape[0], \\\n",
    "ads.loc[(ads.classification == 'sink') & (ads.classification == ads.xg_new) ].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library</th>\n",
       "      <th>method</th>\n",
       "      <th>total</th>\n",
       "      <th>detected</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wear</td>\n",
       "      <td>sources</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>40.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wear</td>\n",
       "      <td>sinks</td>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>8.988764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tv</td>\n",
       "      <td>sources</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv</td>\n",
       "      <td>sources</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analytic</td>\n",
       "      <td>sources</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>51.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>analytic</td>\n",
       "      <td>sinks</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ads</td>\n",
       "      <td>source</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ads</td>\n",
       "      <td>sink</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>92.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    library   method  total  detected       perc\n",
       "0      wear  sources     32        13  40.625000\n",
       "1      wear    sinks     89         8   8.988764\n",
       "2        tv  sources      3         0   0.000000\n",
       "3        tv  sources     14         0   0.000000\n",
       "4  analytic  sources     29        15  51.724138\n",
       "5  analytic    sinks      9         3  33.333333\n",
       "6       ads   source     63         0   0.000000\n",
       "7       ads     sink     14        13  92.857143"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results are slightly different than the paper due to the model used\n",
    "totals_df = pd.DataFrame(totals,columns=['library','method','total','detected'])\n",
    "totals_df['perc'] = (totals_df.detected / totals_df.total) * 100\n",
    "totals_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
