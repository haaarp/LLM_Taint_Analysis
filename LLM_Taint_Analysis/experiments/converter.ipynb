{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fe2e6aa-0dc5-40c5-b0e7-8c4752c6ff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de9fbeda-5147-4210-a936-d12bd3377293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_files(base_url, start_pattern):\n",
    "    # Ensure the save directory exists\n",
    "    save_directory = \"../inputs/yml_files/\"\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    \n",
    "    # List contents of directory\n",
    "    contents = requests.get(base_url).json()\n",
    "    \n",
    "    for item in contents:\n",
    "        # Check if the item is a file and starts with the pattern\n",
    "        if item['type'] == 'file' and item['name'].startswith(start_pattern):\n",
    "            file_url = item['download_url']\n",
    "            # Download the file\n",
    "            file_content = requests.get(file_url).content\n",
    "            file_name = item['name']\n",
    "            # Save the file with the full path\n",
    "            with open(os.path.join(save_directory, file_name), 'wb') as file:\n",
    "                file.write(file_content)\n",
    "        elif item['type'] == 'dir':\n",
    "            # Recursively check in directories\n",
    "            download_files(item['url'], start_pattern)\n",
    "\n",
    "# GitHub API URL for the contents of the directory\n",
    "api_url = \"https://api.github.com/repos/github/codeql/contents/java/ql/lib/ext\"\n",
    "# Pattern to match filenames\n",
    "pattern = \"org.apache.commons\"\n",
    "\n",
    "# Call the function with the API URL and the filename pattern\n",
    "download_files(api_url, pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9929cd3b-4b7a-4b25-96b5-90a6caaf5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_all_href_data_from_file(html_file_path):\n",
    "    # Load HTML file content\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all <a> tags that have an 'href' attribute\n",
    "    a_tags = soup.find_all('a', href=lambda href: href and href.startswith('#'))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # Extract text and any related information for each <a> tag\n",
    "    for a_tag in a_tags:\n",
    "        href = a_tag['href']\n",
    "        # Try to find a related description in a sibling <div>\n",
    "        parent_div = a_tag.find_parent('div')\n",
    "        description_text = \"No description found.\"\n",
    "        if parent_div:\n",
    "            next_div = parent_div.find_next_sibling('div')\n",
    "            if next_div and next_div.find('div', class_='block'):\n",
    "                description_text = next_div.find('div', class_='block').text.strip()\n",
    "                results.append({'href': href[1:], 'description': description_text})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f557355d-c01f-406f-8c0f-d7f27690bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def scrape_all_html_data(class_name, function):\n",
    "    # Output CSV file path\n",
    "    html_file_path = f\"../inputs/html_files/{class_name}_{function}.html\"\n",
    "    \n",
    "    # [\"org.apache.commons.io\", \"FileUtils\", False, \"forceMkdir\",\n",
    "    # URL of the webpage you want to download\n",
    "    sub_class = class_name.split('.')\n",
    "    index_of_commons = sub_class.index('commons')\n",
    "    if len(sub_class) - index_of_commons > 2:\n",
    "        url = f\"https://commons.apache.org/proper/commons-{sub_class[index_of_commons + 1]}/apidocs/org/apache/commons/{sub_class[index_of_commons + 1]}/{sub_class[index_of_commons + 2]}/{function}.html\"\n",
    "    else:\n",
    "        url = f\"https://commons.apache.org/proper/commons-{sub_class[index_of_commons + 1]}/apidocs/org/apache/commons/{sub_class[index_of_commons + 1]}/{function}.html\"\n",
    "    print(url)\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the HTML content to a local file\n",
    "        with open(html_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(response.text)\n",
    "        print(\"File downloaded successfully!\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfbf8bd8-cddb-4e49-9a81-a147b0207efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://commons.apache.org/proper/commons-exec/apidocs/org/apache/commons/exec/environment/EnvironmentUtils.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.exec.environment_EnvironmentUtils_addVariableToEnvironment_(Map_String)\n",
      "https://commons.apache.org/proper/commons-exec/apidocs/org/apache/commons/exec/launcher/CommandLauncher.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.exec.launcher_CommandLauncher_exec_\n",
      "https://commons.apache.org/proper/commons-exec/apidocs/org/apache/commons/exec/CommandLine.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.exec_CommandLine_parse_(String)\n",
      "org.apache.commons.exec_CommandLine_parse_(String_Map)\n",
      "org.apache.commons.exec_CommandLine_addArguments_(String)\n",
      "org.apache.commons.exec_CommandLine_addArguments_(String_boolean)\n",
      "org.apache.commons.exec_CommandLine_addArguments_(String[])\n",
      "org.apache.commons.exec_CommandLine_addArguments_(String[]_boolean)\n",
      "org.apache.commons.exec_Executor_execute_(CommandLine_Map)\n",
      "org.apache.commons.exec_Executor_execute_(CommandLine_Map_ExecuteResultHandler)\n",
      "https://commons.apache.org/proper/commons-io/apidocs/org/apache/commons/io/FileUtils.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.io_FileUtils_forceMkdir_(File)\n",
      "org.apache.commons.io_FileUtils_moveDirectory_(File_File)\n",
      "org.apache.commons.io_FileUtils_readFileToByteArray_(File)\n",
      "org.apache.commons.io_FileUtils_readFileToString_(File_Charset)\n",
      "org.apache.commons.io_FileUtils_writeLines_(File_String_Collection_String)\n",
      "org.apache.commons.io_FileUtils_writeStringToFile_(File_String_Charset_boolean)\n",
      "org.apache.commons.io_FileUtils_copyInputStreamToFile_(InputStream_File)\n",
      "org.apache.commons.io_FileUtils_copyInputStreamToFile_(InputStream_File)\n",
      "org.apache.commons.io_FileUtils_copyToFile_(InputStream_File)\n",
      "org.apache.commons.io_FileUtils_copyToFile_(InputStream_File)\n",
      "org.apache.commons.io_FileUtils_openInputStream_(File)\n",
      "org.apache.commons.io_IOUtils_resourceToString_(String_Charset)\n",
      "https://commons.apache.org/proper/commons-jelly/apidocs/org/apache/commons/jelly/JellyContext.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.jelly_JellyContext_JellyContext_(JellyContext_URL_URL)\n",
      "org.apache.commons.jelly_JellyContext_JellyContext_(JellyContext_URL_URL)\n",
      "org.apache.commons.jelly_JellyContext_JellyContext_(JellyContext_URL)\n",
      "org.apache.commons.jelly_JellyContext_JellyContext_(URL_URL)\n",
      "org.apache.commons.jelly_JellyContext_JellyContext_(URL_URL)\n",
      "org.apache.commons.jelly_JellyContext_JellyContext_(URL)\n",
      "https://commons.apache.org/proper/commons-jexl2/apidocs/org/apache/commons/jexl2/Expression.html\n",
      "Failed to retrieve the webpage. Status code: 404\n",
      "org.apache.commons.jexl2_Expression_callable_\n",
      "org.apache.commons.jexl2_Expression_evaluate_\n",
      "org.apache.commons.jexl2_JexlEngine_getProperty_(JexlContext_Object_String)\n",
      "org.apache.commons.jexl2_JexlEngine_getProperty_(Object_String)\n",
      "org.apache.commons.jexl2_JexlEngine_setProperty_(JexlContext_Object_String_Object)\n",
      "org.apache.commons.jexl2_JexlEngine_setProperty_(Object_String_Object)\n",
      "org.apache.commons.jexl2_JexlExpression_callable_\n",
      "org.apache.commons.jexl2_JexlExpression_evaluate_\n",
      "org.apache.commons.jexl2_JexlScript_callable_\n",
      "org.apache.commons.jexl2_JexlScript_execute_\n",
      "org.apache.commons.jexl2_Script_callable_\n",
      "org.apache.commons.jexl2_Script_execute_\n",
      "org.apache.commons.jexl2_UnifiedJEXL$Expression_evaluate_\n",
      "org.apache.commons.jexl2_UnifiedJEXL$Expression_prepare_\n",
      "org.apache.commons.jexl2_UnifiedJEXL$Template_evaluate_\n",
      "https://commons.apache.org/proper/commons-jexl3/apidocs/org/apache/commons/jexl3/Expression.html\n",
      "Failed to retrieve the webpage. Status code: 404\n",
      "org.apache.commons.jexl3_Expression_callable_\n",
      "org.apache.commons.jexl3_Expression_evaluate_\n",
      "org.apache.commons.jexl3_JexlEngine_getProperty_(JexlContext_Object_String)\n",
      "org.apache.commons.jexl3_JexlEngine_getProperty_(Object_String)\n",
      "org.apache.commons.jexl3_JexlEngine_setProperty_(JexlContext_Object_String)\n",
      "org.apache.commons.jexl3_JexlEngine_setProperty_(Object_String_Object)\n",
      "org.apache.commons.jexl3_JexlExpression_callable_\n",
      "org.apache.commons.jexl3_JexlExpression_evaluate_\n",
      "org.apache.commons.jexl3_JexlScript_callable_\n",
      "org.apache.commons.jexl3_JexlScript_execute_\n",
      "org.apache.commons.jexl3_JxltEngine$Expression_evaluate_\n",
      "org.apache.commons.jexl3_JxltEngine$Expression_prepare_\n",
      "org.apache.commons.jexl3_JxltEngine$Template_evaluate_\n",
      "org.apache.commons.jexl3_Script_callable_\n",
      "org.apache.commons.jexl3_Script_execute_\n",
      "https://commons.apache.org/proper/commons-lang3/apidocs/org/apache/commons/lang3/RegExUtils.html\n",
      "Failed to retrieve the webpage. Status code: 404\n",
      "org.apache.commons.lang3_RegExUtils_removeAll_(String_String)\n",
      "org.apache.commons.lang3_RegExUtils_removeFirst_(String_String)\n",
      "org.apache.commons.lang3_RegExUtils_removePattern_(String_String)\n",
      "org.apache.commons.lang3_RegExUtils_replaceAll_(String_String_String)\n",
      "org.apache.commons.lang3_RegExUtils_replaceFirst_(String_String_String)\n",
      "org.apache.commons.lang3_RegExUtils_replacePattern_(String_String_String)\n",
      "https://commons.apache.org/proper/commons-logging/apidocs/org/apache/commons/logging/Log.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.logging_Log_debug_\n",
      "org.apache.commons.logging_Log_error_\n",
      "org.apache.commons.logging_Log_fatal_\n",
      "org.apache.commons.logging_Log_info_\n",
      "org.apache.commons.logging_Log_trace_\n",
      "org.apache.commons.logging_Log_warn_\n",
      "https://commons.apache.org/proper/commons-net/apidocs/org/apache/commons/net/ftp/FTPClient.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.net.ftp_FTPClient_login_(String_String)\n",
      "org.apache.commons.net.ftp_FTPClient_login_(String_String)\n",
      "org.apache.commons.net.ftp_FTPClient_login_(String_String_String)\n",
      "org.apache.commons.net.ftp_FTPClient_login_(String_String_String)\n",
      "https://commons.apache.org/proper/commons-net/apidocs/org/apache/commons/net/SocketClient.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.net_SocketClient_connect_(InetAddress)\n",
      "org.apache.commons.net_SocketClient_connect_(InetAddress_int)\n",
      "org.apache.commons.net_SocketClient_connect_(InetAddress_int_InetAddress_int)\n",
      "org.apache.commons.net_SocketClient_connect_(String)\n",
      "org.apache.commons.net_SocketClient_connect_(String_int)\n",
      "org.apache.commons.net_SocketClient_connect_(String_int_InetAddress_int)\n",
      "https://commons.apache.org/proper/commons-net/apidocs/org/apache/commons/net/util/KeyManagerUtils.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.net.util_KeyManagerUtils_createClientKeyManager_(File_String)\n",
      "org.apache.commons.net.util_KeyManagerUtils_createClientKeyManager_(File_String_String)\n",
      "org.apache.commons.net.util_KeyManagerUtils_createClientKeyManager_(String_File_String_String_String)\n",
      "https://commons.apache.org/proper/commons-net/apidocs/org/apache/commons/net/ftp/FTPClient.html\n",
      "File downloaded successfully!\n",
      "org.apache.commons.net.ftp_FTPClient_listDirectories_()\n",
      "org.apache.commons.net.ftp_FTPClient_listDirectories_(String)\n",
      "org.apache.commons.net.ftp_FTPClient_listFiles_()\n",
      "org.apache.commons.net.ftp_FTPClient_listFiles_(String)\n",
      "org.apache.commons.net.ftp_FTPClient_listFiles_(String_FTPFileFilter)\n",
      "org.apache.commons.net.ftp_FTPClient_listNames_()\n",
      "org.apache.commons.net.ftp_FTPClient_listNames_(String)\n",
      "org.apache.commons.net.ftp_FTPClient_mlistDir_()\n",
      "org.apache.commons.net.ftp_FTPClient_mlistDir_(String)\n",
      "org.apache.commons.net.ftp_FTPClient_mlistDir_(String_FTPFileFilter)\n",
      "org.apache.commons.net.ftp_FTPClient_retrieveFile_(String_OutputStream)\n",
      "org.apache.commons.net.ftp_FTPClient_retrieveFileStream_(String)\n",
      "https://commons.apache.org/proper/commons-ognl/apidocs/org/apache/commons/ognl/enhance/ExpressionAccessor.html\n",
      "Failed to retrieve the webpage. Status code: 404\n",
      "org.apache.commons.ognl.enhance_ExpressionAccessor_get_\n",
      "org.apache.commons.ognl.enhance_ExpressionAccessor_set_\n",
      "https://commons.apache.org/proper/commons-ognl/apidocs/org/apache/commons/ognl/Node.html\n",
      "Failed to retrieve the webpage. Status code: 404\n",
      "org.apache.commons.ognl_Node_getValue_\n",
      "org.apache.commons.ognl_Node_setValue_\n",
      "org.apache.commons.ognl_Ognl_getValue_\n",
      "org.apache.commons.ognl_Ognl_setValue_\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Directory containing the YAML files\n",
    "directory_path = '../inputs/yml_files'\n",
    "\n",
    "# Output CSV file path\n",
    "csv_file_path = '../inputs/new_API.csv'\n",
    "\n",
    "# Failed CSV file path\n",
    "error_log_path = '../inputs/error_log.csv'\n",
    "\n",
    "# Prepare the header for the CSV file\n",
    "header = ['keys', 'docs', 'real']\n",
    "\n",
    "# List to hold all CSV data from multiple YAML files\n",
    "csv_data = []\n",
    "\n",
    "# List to hold errors\n",
    "error_data = []\n",
    "\n",
    "# Function to process each YAML file\n",
    "def process_yaml_file(file_path, csv_data):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        for ext in data.get('extensions', []):\n",
    "            extensible_type = ext['addsTo'].get('extensible', '')\n",
    "            if extensible_type in ['sourceModel', 'sinkModel']:\n",
    "                model_type = 'source' if extensible_type == 'sourceModel' else 'sink'\n",
    "                prev_class = \"\"\n",
    "                for item in ext.get('data', []):\n",
    "                    class_name, function, method, parameters = item[0], item[1], item[3], item[4]\n",
    "                    # New package that needed to be scraped\n",
    "                    sub_class_name = class_name.split('.')[-1]\n",
    "                    if sub_class_name != prev_class:\n",
    "                        prev_class = sub_class_name\n",
    "                        scrape_all_html_data(class_name, function)\n",
    "    \n",
    "                    # scrape_all_html_data(class_name, function)\n",
    "                    # Generate a unique key using class, method, and parameters\n",
    "                    key = f\"{class_name}_{function}_{method}_{parameters.replace(',', '_')}\"\n",
    "                    print(key)\n",
    "                    # find the description\n",
    "                    des = \"\"\n",
    "                    html_file_path = f\"../inputs/html_files/{class_name}_{function}.html\"  \n",
    "                    try:\n",
    "                        all_href_data = extract_all_href_data_from_file(html_file_path)\n",
    "                        for data in all_href_data:\n",
    "                            if '(' in data['href']:\n",
    "                                method_name, param_section = data['href'].split('(')\n",
    "                                param_section = param_section.strip(')')\n",
    "    \n",
    "                            else:\n",
    "                                method_name = data['href']\n",
    "                                param_section = \"\"\n",
    "                                \n",
    "                            params = param_section.split(',')\n",
    "                            abbreviated_params = [param.strip().split('.')[-1] for param in params]\n",
    "                            if '(' in parameters:\n",
    "                                parameters = parameters[1:-1]\n",
    "                                \n",
    "                            if method_name == method and parameters.split(',') == abbreviated_params:\n",
    "                                des = data['description']\n",
    "                                break\n",
    "                    except Exception as e:\n",
    "                        error_data.append([class_name, function, str(e)])\n",
    "                    csv_data.append([key, des, model_type])\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.yml'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        process_yaml_file(file_path, csv_data)\n",
    "\n",
    "# Write all the data to a single CSV file\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(csv_data)\n",
    "    \n",
    "# Write error data to error log file\n",
    "with open(error_log_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Class Name', 'Function Name', 'Error Message'])\n",
    "    writer.writerows(error_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d6994-9467-4f98-8973-f7ebcb7c4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "new website: https://commons.apache.org/proper/commons-lang/javadocs\n",
    "old website:https://commons.apache.org/proper/commons-lang/javadocs/api-3.0/\n",
    "old website: https://commons.apache.org/proper/commons-lang/javadocs/api-3.1/org/apache/commons/lang3/builder/ToStringBuilder.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
